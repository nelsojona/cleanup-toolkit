[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "cleanup-toolkit"
version = "1.0.0"
description = "Agentic Code Cleanup Toolkit - AI-powered code cleanup for development workflows"
readme = "README.md"
requires-python = ">=3.9"
license = {text = "MIT"}
authors = [
    {name = "Cleanup Toolkit Contributors", email = "contact@cleanup-toolkit.dev"}
]
keywords = ["cleanup", "code-quality", "ai", "development-tools", "git", "pre-commit"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Quality Assurance",
    "Topic :: Software Development :: Version Control :: Git",
]

[project.urls]
Homepage = "https://github.com/cleanup-toolkit/cleanup-toolkit"
Documentation = "https://cleanup-toolkit.dev/docs"
Repository = "https://github.com/cleanup-toolkit/cleanup-toolkit"
Issues = "https://github.com/cleanup-toolkit/cleanup-toolkit/issues"

[project.optional-dependencies]
dev = [
    "black>=23.7.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "pylint>=2.17.4",
    "mypy>=1.4.1",
]
test = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.11.1",
    "pytest-asyncio>=0.21.0",
    "pytest-timeout>=2.1.0",
    "pytest-xdist>=3.3.1",
    "coverage[toml]>=7.2.7",
]

[tool.setuptools]
packages = ["tests"]

[tool.setuptools.package-data]
"*" = ["*.md", "*.txt", "*.yml", "*.yaml", "*.sh"]

# ==================== Testing Configuration ====================

[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-ra",
    "--strict-markers",
    "--ignore=docs",
    "--ignore=build",
    "--ignore=dist",
    "--cov=.",
    "--cov-branch",
    "--cov-report=term-missing:skip-covered",
    "--cov-report=html",
    "--cov-report=xml",
    "--cov-fail-under=80",
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests", 
    "e2e: End-to-end tests",
    "performance: Performance tests",
    "security: Security tests",
    "slow: Slow running tests",
    "requires_git: Tests requiring git",
    "requires_network: Tests requiring network access",
]
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
]

# ==================== Coverage Configuration ====================

[tool.coverage.run]
branch = true
source = ["."]
omit = [
    "*/tests/*",
    "*/test_*.py",
    "*/__pycache__/*",
    "*/site-packages/*",
    "*/dist-packages/*",
    "*/venv/*",
    "*/env/*",
    "*/.venv/*",
    "*/.env/*",
    "*/setup.py",
    "*/conftest.py",
]
parallel = true
relative_files = true

[tool.coverage.report]
precision = 2
show_missing = true
skip_covered = false
skip_empty = true
sort = "Cover"
exclude_lines = [
    # Standard pragma
    "pragma: no cover",
    
    # Don't complain about missing debug-only code
    "def __repr__",
    "if self.debug",
    "if DEBUG",
    
    # Don't complain if tests don't hit defensive assertion code
    "raise AssertionError",
    "raise NotImplementedError",
    
    # Don't complain if non-runnable code isn't run
    "if 0:",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
    
    # Don't complain about abstract methods
    "@(abc.)?abstractmethod",
]
ignore_errors = true

[tool.coverage.html]
directory = "htmlcov"
title = "Cleanup Toolkit Coverage Report"
show_contexts = true

[tool.coverage.xml]
output = "coverage.xml"

[tool.coverage.json]
output = "coverage.json"
pretty_print = true
show_contexts = true

# ==================== Code Quality Configuration ====================

[tool.black]
line-length = 100
target-version = ['py39', 'py310', 'py311', 'py312']
include = '\.pyi?$'
extend-exclude = '''
/(
    \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
  | tests/fixtures
)/
'''

[tool.isort]
profile = "black"
line_length = 100
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
skip_glob = ["*/migrations/*", "*/fixtures/*"]

[tool.pylint.messages_control]
disable = [
    "C0111",  # missing-docstring
    "C0103",  # invalid-name
    "R0903",  # too-few-public-methods
    "R0913",  # too-many-arguments
    "W0212",  # protected-access
    "C0301",  # line-too-long (handled by black)
]

[tool.pylint.format]
max-line-length = 100

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
disallow_any_generics = false
ignore_missing_imports = true
follow_imports = "silent"
no_implicit_reexport = true
strict_optional = true
strict_equality = true
check_untyped_defs = true
namespace_packages = true
show_error_codes = true
show_column_numbers = true
pretty = true

# ==================== Performance Testing Configuration ====================

[tool.pytest-benchmark]
min_rounds = 5
max_time = 1.0
min_time = 0.000005
timer = "perf_counter"
calibration_precision = 10
warmup = true
warmup_iterations = 100000
disable_gc = true
pedantic = false
verbose = false
sort = "min"
group_by = "group"
columns = ["min", "max", "mean", "stddev", "median", "iqr", "outliers", "rounds", "iterations"]
save = "benchmarks"
autosave = false
compare = false
compare_fail = ["min:5%", "median:5%"]